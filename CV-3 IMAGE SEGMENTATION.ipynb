{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image\n",
    "image=cv2.imread('images/shapes.jpg')\n",
    "cv2.imshow('Input Image',image)\n",
    "\n",
    "#Grayscale\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "#Find Canny edges (find where intensite changes occur=borders)\n",
    "edged=cv2.Canny(gray,30,200)\n",
    "cv2.imshow('Canny Edges',edged)\n",
    "\n",
    "#Find countours\n",
    "_,contours, hierarchy=cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Canny Edges After Contouring',edged)\n",
    "print('Number of Contours found =',len(contours))\n",
    "\n",
    "# Draw all contours\n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "\n",
    "cv2.drawContours(image, contours, -1,(0,255,0),3)\n",
    "cv2.imshow('Contours',image)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv2.findContours(image, Retrieval Mode, Approximation Method)**\n",
    "\n",
    "Returns -> contours, hierarchy\n",
    "\n",
    "**NOTE** In OpenCV 3.X, findContours returns a 3rd argument which is ret (or a boolean indicating if the function was successfully run). \n",
    "\n",
    "If you're using OpenCV 3.X replace line 12 with:\n",
    "\n",
    "_, contours, hierarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "The variable 'contours' are stored as a numpy array of (x,y) points that form the contour\n",
    "\n",
    "While, 'hierarchy' describes the child-parent relationships between contours (i.e. contours within contours)\n",
    "\n",
    "\n",
    "\n",
    "#### Approximation Methods\n",
    "\n",
    "Using cv2.CHAIN_APPROX_NONE stores all the boundary points. But we don't necessarily need all bounding points. If the points form a straight line, we only need the start and ending points of that line.\n",
    "\n",
    "Using cv2.CHAIN_APPROX_SIMPLE instead only provides these start and end points of bounding contours, thus resulting in much more efficent storage of contour information..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours found= 4\n"
     ]
    }
   ],
   "source": [
    "image=cv2.imread('images/bunchofshapes.jpg')\n",
    "cv2.imshow('0 - Original Image',image)\n",
    "\n",
    "# Create a black image with same dimensions as our loaded image\n",
    "blank_image = np.zeros((image.shape[0],image.shape[1],3))\n",
    "cv2.imshow('Created',blank_image)\n",
    "\n",
    "#create a copy of our original image\n",
    "original_image=image\n",
    "\n",
    "#Grayscale our image\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "#Find canny edges\n",
    "edged=cv2.Canny(gray,50,200)\n",
    "cv2.imshow('1 - Canny Edges',edged)\n",
    "\n",
    "#Find contours and print how many were found\n",
    "_,contours, hierarchy=cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "print('Number of contours found=',len(contours))\n",
    "\n",
    "#Draw all contours over blank image\n",
    "cv2.drawContours(blank_image,contours,-1,(0,255,0),3)\n",
    "cv2.imshow('2 - All Contours over blank image',blank_image)\n",
    "\n",
    "#Draw all contours over origina image\n",
    "cv2.drawContours(image,contours,-1,(0,255,0),3)\n",
    "cv2.imshow('2 - All Contours over blank image',image)\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now sort by area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour Area before sorting\n",
      "[20587.5, 22900.5, 66581.5, 90222.0]\n",
      "Contour Area After sorting\n",
      "[90222.0, 66581.5, 22900.5, 20587.5]\n"
     ]
    }
   ],
   "source": [
    "# Function we'll use to display contour area\n",
    "def get_contours_areas(contours):\n",
    "    #return the areas of all contours as list\n",
    "    all_areas = []\n",
    "    for cnt in contours:\n",
    "        area=cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    return all_areas\n",
    "\n",
    "#Load our image\n",
    "image=cv2.imread('images/bunchofshapes.jpg')\n",
    "original_image=image\n",
    "\n",
    "#Let's print the areas of the contours before sorting\n",
    "print('Contour Area before sorting')\n",
    "_,contours, hierarchy=cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "print(get_contours_areas(contours))\n",
    "\n",
    "\n",
    "#sort contours large to small\n",
    "sorted_contours=sorted(contours,key=cv2.contourArea,reverse=True)\n",
    "#sorted_contours=sorted(contours,key=cv2.contourArea,reverse=True)[:3]\n",
    "print('Contour Area After sorting')\n",
    "print(get_contours_areas(sorted_contours))\n",
    "\n",
    "\n",
    "#Iterate over our contour and draw one at a time\n",
    "for c in sorted_contours:\n",
    "    cv2.drawContours(original_image, [c],-1,(255,0,0),3)\n",
    "    cv2.waitKey()\n",
    "    cv2.imshow('Contours by area',original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now sort by Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_shape_number_1.jpg\n",
      "output_shape_number_2.jpg\n",
      "output_shape_number_3.jpg\n",
      "output_shape_number_4.jpg\n"
     ]
    }
   ],
   "source": [
    "# Functions we'll use for sorting by position\n",
    "def x_cord_contour(contours):\n",
    "    #Return the X cordinate for the contour centroid\n",
    "    if cv2.contourArea(contours)>10:\n",
    "        M=cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def label_contour_center(image,c):#c is a contour\n",
    "    #Place a red circle on the centers of contours\n",
    "    M=cv2.moments(c)#M the center of the image\n",
    "    cx=int(M['m10']/M['m00'])\n",
    "    cy=int(M['m01']/M['m00'])\n",
    "    #Draw the contour number on the image\n",
    "    cv2.circle(image,(cx,cy),10,(0,0,255),-1)\n",
    "    return image\n",
    "\n",
    "\n",
    "#Load our image\n",
    "image=cv2.imread('images/bunchofshapes.jpg')\n",
    "original_image=image.copy()\n",
    "\n",
    "#Compute Center of Mass or Centroids and draw them on our image\n",
    "for (i,c)in enumerate(contours):#i=1,2,... and c=area of contour\n",
    "    orig=label_contour_center(image,c)\n",
    "cv2.imshow('4 - Contour Centers',image)\n",
    "\n",
    "#Sort by left to right using our x_cord_contour function\n",
    "contours_left_to_right = sorted(contours,key=x_cord_contour,reverse=False)\n",
    "\n",
    "#Labeling Contours left to right\n",
    "for (i,c) in enumerate(contours_left_to_right):\n",
    "    cv2.drawContours(original_image,[c],-1,(0,0,255),3)\n",
    "    M=cv2.moments(c)\n",
    "    cx=int(M['m10']/M['m00'])\n",
    "    cy=int(M['m01']/M['m00'])\n",
    "    cv2.putText(original_image, str(i+1),(cx,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.imshow('6 - Left to Right Contour',original_image)\n",
    "    cv2.waitKey()\n",
    "    \n",
    "    \n",
    "    # Let's now crop each contour and save these images\n",
    "    (x, y, w, h) = cv2.boundingRect(c) #Contour bounding Rectangle \n",
    "    cropped_contour = original_image[y:y + h, x:x + w]\n",
    "    image_name='output_shape_number_'+ str(i+1)+'.jpg'\n",
    "    print(image_name)\n",
    "    cv2.imwrite( image_name,cropped_contour)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating Contours and Convex Hull \n",
    "\n",
    "***cv2.approxPolyDP(contour, Approximation Accuracy, Closed)***\n",
    "- **contour** – is the individual contour we wish to approximate\n",
    "- **Approximation Accuracy** – Important parameter is determining the accuracy of the approximation. Small values give precise-  approximations, large values give more generic approximation. A good rule of thumb is less than 5% of the contour perimeter\n",
    "- **Closed** – a Boolean value that states whether the approximate contour should be open or closed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image and keep a copy\n",
    "image=cv2.imread('images/house.jpg')\n",
    "orig_image=image.copy()\n",
    "cv2.imshow('Original Image',orig_image)\n",
    "\n",
    "# Grayscale and binarize\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh=cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Grayscale and binarize',gray)\n",
    "\n",
    "# Find contours \n",
    "_,contours,hierarchy=cv2.findContours(thresh.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Iterate through each contour and compute the bounding rectangle\n",
    "for c in contours:\n",
    "    x,y,w,h=cv2.boundingRect(c)\n",
    "    cv2.rectangle(orig_image,(x,y),(x+w,y+w),(0,0,255),2)\n",
    "    cv2.imshow('Bounding Rectangle',orig_image)\n",
    "    \n",
    "# Iterate through each contour and compute the approx contour\n",
    "for c in contours:\n",
    "    #Calculate accuracy as a percent of the contour perimeter\n",
    "    accuracy=0.03*cv2.arcLength(c,True)\n",
    "    approx=cv2.approxPolyDP(c,accuracy,True)\n",
    "    cv2.drawContours(image, [approx],0,(0,255,0),2)\n",
    "    cv2.imshow('approx Poly DP',image)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('images/hand.jpg')\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Original Image',image)\n",
    "\n",
    "#Threshold the image\n",
    "ret,thresh=cv2.threshold(gray,176,255,0)\n",
    "#Find contours\n",
    "_,contours,hierarchy=cv2.findContours(thresh.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.drawContours(image,contours,-1,(0,255,0),3)\n",
    "cv2.imshow('All Contours',image)\n",
    "\n",
    "\n",
    "# Sort Contors by area and then remove the largest frame contour\n",
    "n=len(contours)-1\n",
    "contours=sorted(contours,key=cv2.contourArea,reverse=False)[:n]\n",
    "# Iterate through contours and draw the convex hull\n",
    "for c in contours:\n",
    "    hull=cv2.convexHull(c)\n",
    "    cv2.drawContours(image,[hull],0,(0,255,0),2)\n",
    "    cv2.imshow('Convex Hull',image)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape Matching\n",
    "\n",
    "**cv2.matchShapes(contour template, contour, method, method parameter)**\n",
    "\n",
    "**Output** – match value (lower values means a closer match)\n",
    "\n",
    "- Contour Template – This is our reference contour that we’re trying to find in the new image\n",
    "- Contour – The individual contour we are checking against\n",
    "- Method – Type of contour matching (1, 2, 3)\n",
    "- Method Parameter – leave alone as 0.0 (not fully utilized in python OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13081816783853514\n",
      "0.1590200533978871\n",
      "0.1498791568252558\n",
      "0.07094034474475601\n"
     ]
    }
   ],
   "source": [
    "# Load the shape template or reference image\n",
    "template=cv2.imread('images/4star.jpg',0)\n",
    "cv2.imshow('Template',template)\n",
    "\n",
    "\n",
    "# Load the target image with the shapes we're trying to match\n",
    "target=cv2.imread('images/shapestomatch.jpg')\n",
    "target_gray=cv2.cvtColor(target,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Target',target_gray)\n",
    "\n",
    "# Threshold both images first before using cv2.findContours\n",
    "ret,thresh1=cv2.threshold(template,127,255,0)\n",
    "ret,thresh2=cv2.threshold(target_gray,127,255,0)\n",
    "\n",
    "#Find contours in template\n",
    "_,contours, hierarchy=cv2.findContours(thresh1,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "# We need to sort the contours by area so that we can remove the largest\n",
    "# contour which is the image outline\n",
    "sorted_contours=sorted(contours, key=cv2.contourArea,reverse=True)\n",
    "# We extract the second largest contour which will be our template contour\n",
    "template_contour=contours[1]\n",
    "# Extract contours from second target image\n",
    "_,contours,hierarchy=cv2.findContours(thresh2,cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "for c in contours:\n",
    "    # Iterate through each contour in the target image and \n",
    "    # use cv2.matchShapes to compare contour shapes\n",
    "    match=cv2.matchShapes(template_contour,c,3,0.0)\n",
    "    print(match)\n",
    "    if match < 0.15:\n",
    "        closest_contour=c\n",
    "    else:\n",
    "        closest_contour=[]\n",
    "        \n",
    "cv2.drawContours(target,[closest_contour],-1,(0,255,0),3)\n",
    "cv2.imshow('Output',target)\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Project 2 - Identifiy Contours by Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and then gray scale image\n",
    "image=cv2.imread('images/someshapes.jpg')\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Identifying Shapes Original',image.copy())\n",
    "\n",
    "#Thresholding\n",
    "ret,thresh=cv2.threshold(gray,127,255,1)\n",
    "#Extract Contours\n",
    "_,contours,hierarchy=cv2.findContours(thresh.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\n",
    "for cnt in contours:\n",
    "    #Get approximate polygons\n",
    "    approx=cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)\n",
    "    \n",
    "    if len(approx)==3:\n",
    "        shape_name='Triangle'\n",
    "        cv2.drawContours(image,[cnt],0,(0,255,0),-1)\n",
    "        #Find contour center to place text at the center\n",
    "        M=cv2.moments(cnt)\n",
    "        cx=int(M['m10']/M['m00'])\n",
    "        cy=int(M['m01']/M['m00'])\n",
    "        cv2.putText(image,shape_name,(cx-50,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),1)\n",
    "    \n",
    "    elif len(approx)==4:\n",
    "        x,y,w,h=cv2.boundingRect(cnt)\n",
    "        M=cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])    \n",
    "        # Check to see if 4-side polygon is square or rectangle\n",
    "        # cv2.boundingRect returns the top left and then width and\n",
    "        if abs(w-h)<=3:\n",
    "            shape_name='Square'\n",
    "            #Find contour center to place text at the center\n",
    "            # Find contour center to place text at the center\n",
    "            cv2.drawContours(image, [cnt], 0, (0, 125 ,255), -1)\n",
    "            cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        else:\n",
    "            shape_name = \"Rectangle\"\n",
    "            \n",
    "            # Find contour center to place text at the center\n",
    "            cv2.drawContours(image, [cnt], 0, (0, 0, 255), -1)\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "    \n",
    "    \n",
    "    elif len(approx) == 10:\n",
    "        shape_name = \"Star\"\n",
    "        cv2.drawContours(image, [cnt], 0, (255, 255, 0), -1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif len(approx) >= 15:\n",
    "        shape_name = \"Circle\"\n",
    "        cv2.drawContours(image, [cnt], 0, (0, 255, 255), -1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "\n",
    "            \n",
    "            \n",
    "cv2.imshow('Identifying Shapes',image)            \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Line Detection - Using Hough Lines\n",
    "   \n",
    "**cv2.HoughLines**(binarized/thresholded image, 𝜌 accuracy, 𝜃 accuracy, threshold)\n",
    "- Threshold here is the minimum vote for it to be considered a line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2925, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "image=cv2.imread('images/soduku.jpg')\n",
    "cv2.imshow('Original image',image)\n",
    "\n",
    "#Grayscale and Canny Edges extracted\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "edges=cv2.Canny(gray, 100,170,apertureSize = 7)\n",
    "\n",
    "#Run HoughLines using a rho accuracy of 1 pixel\n",
    "# theta accuracy of np.pi / 180 which is 1 degree\n",
    "# Our line threshold is set to 240 (number of points on line)\n",
    "lines=cv2.HoughLines(edges,1,np.pi/180,240)\n",
    "print(lines.shape) \n",
    "\n",
    "\n",
    "# We iterate through each line and convert it to the format\n",
    "# required by cv.lines (i.e. requiring end points)\n",
    "for rho,theta in lines[0]:\n",
    "    a=np.cos(theta)\n",
    "    b=np.sin(theta)\n",
    "    x0=a*rho\n",
    "    y0=b*rho\n",
    "    x1=int(x0+1000*(-b))\n",
    "    y1=int(y0+1000*(a))\n",
    "    x2=int(x0-1000*(-b))\n",
    "    y2=int(y0-1000*(a))\n",
    "    cv2.line(image,(x1,y1),(x2,y2),(255,0,255),2)\n",
    "cv2.imshow('Hough Lines', image)    \n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Hough Lines\n",
    "\n",
    "**cv2.HoughLinesP(binarized image, 𝜌 accuracy, 𝜃 accuracy, threshold, minimum line length, max line gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale and Canny Edges extracted\n",
    "image=cv2.imread('images/soduku.jpg')\n",
    "gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges=cv2.Canny(gray,100,170,apertureSize = 7)\n",
    "\n",
    "# Again we use the same rho and theta accuracies\n",
    "# However, we specify a minimum vote (pts along line) of 100\n",
    "# and Min line length of 5 pixels and max gap between lines of 10 pixels\n",
    "lines=cv2.HoughLinesP(edges,1,np.pi/180,200,5,10)\n",
    "#print(lines.shape)\n",
    "\n",
    "for x1,y1,x2,y2 in lines[0]:\n",
    "    cv2.line(image,(x1,y1),(x2,y2),(255,0,255),2)\n",
    "cv2.imshow('Probabilistic Hough Lines',image)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circle Detection - Hough Cirlces\n",
    "\n",
    "**cv2.HoughCircles**(image, method, dp, MinDist, param1, param2, minRadius, MaxRadius)\n",
    "\n",
    "\n",
    "- Method - currently only cv2.HOUGH_GRADIENT available\n",
    "- dp - Inverse ratio of accumulator resolution\n",
    "- MinDist - the minimum distance between the center of detected circles\n",
    "- param1 - Gradient value used in the edge detection\n",
    "- param2 - Accumulator threshold for the HOUGH_GRADIENT method (lower allows more circles to be detected (false positives))\n",
    "- minRadius - limits the smallest circle to this size (via radius)\n",
    "- MaxRadius - similarly sets the limit for the largest circles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 194.25      317.25       32.758587]\n",
      "  [ 467.25      321.75       32.88807 ]\n",
      "  [ 603.75      408.75       43.938877]\n",
      "  ...\n",
      "  [   8.25      743.25      512.8466  ]\n",
      "  [1022.25       57.75      534.12836 ]\n",
      "  [1022.25       69.75      515.82855 ]]]\n"
     ]
    }
   ],
   "source": [
    "image=cv2.imread('images/bottlecaps.jpg')\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "blur=cv2.medianBlur(gray,5)\n",
    "cv2.imshow('Original image',blur)\n",
    "\n",
    "circles = cv2.HoughCircles(blur,cv2.HOUGH_GRADIENT,1.5,10)\n",
    "                           #param1=30,\n",
    "                           #param2=15,\n",
    "                           #minRadius=0,\n",
    "                           #maxRadius=0)\n",
    "#circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 10)\n",
    "print(circles)\n",
    "circles=np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    #draw the outer circle\n",
    "    cv2.circle(image,(i[0], i[1]), i[2], (255, 0, 0), 2)\n",
    "    #draw the center of the circle\n",
    "    cv2.circle(image,(i[0],i[1]),2,(0,255,0),5)\n",
    "cv2.imshow('detected circles',image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob Detection\n",
    "\n",
    "A Blob is a group of connected pixels in an image that share some common property ( E.g grayscale value ). In the image above, the dark connected regions are blobs, and the goal of blob detection is to identify and mark these regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read image\n",
    "image=cv2.imread('images/Sunflowers.jpg')\n",
    "cv2.imshow('Sunflowers',image)\n",
    "\n",
    "#Set up the detector with default parameters\n",
    "detector = cv2.SimpleBlobDetector_create()\n",
    "#Detect blobs  \n",
    "keypoints = detector.detect(image)\n",
    "\n",
    "#Draw tetected blobs as red circles\n",
    "#cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of \n",
    "#the circle corresponds to the size of blob\n",
    "blank=np.zeros((1,1))\n",
    "blobs=cv2.drawKeypoints(image,keypoints,blank)\n",
    "\n",
    "cv2.imshow(\"Blobs\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **cv2.drawKeypoints** takes the following arguments:\n",
    "\n",
    "**cv2.drawKeypoints**(input image, keypoints, blank_output_array, color, flags)\n",
    "\n",
    "flags:\n",
    "- cv2.DRAW_MATCHES_FLAGS_DEFAULT\n",
    "- cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "- cv2.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG\n",
    "- cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Project # 3 - Counting Circles and Ellipses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image\n",
    "image=cv2.imread('images/blobs.jpg',0)\n",
    "cv2.imshow('Original image',image)\n",
    "\n",
    "# Intialize the detector using the default parameters\n",
    "detector=cv2.SimpleBlobDetector_create()\n",
    "#Detect blobs\n",
    "keypoints=detector.detect(image)\n",
    "#Draw blobs on our image as red circles\n",
    "blank=np.zeros((1,1))\n",
    "blobs=cv2.drawKeypoints(image,keypoints,blank,(0,0,255),\n",
    "                       cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "number_of_blobs=len(keypoints)\n",
    "text='Total Number of Blobs:'+ str(len(keypoints))\n",
    "cv2.putText(blobs,text,(20,550),cv2.FONT_HERSHEY_SIMPLEX,1,(100,0,255),2)\n",
    "\n",
    "#Display image with blob keypoints\n",
    "cv2.imshow('Blobs using default parameters',blobs)\n",
    "\n",
    "#Set out filtering parameters\n",
    "#initialize parameter setting using cv2.SimpleBlobDetector_Params()\n",
    "params=cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "#Set Area filtering paremeters\n",
    "params.filterByArea=True\n",
    "params.minArea=100\n",
    "\n",
    "#Set Circularity filtering paremeters\n",
    "params.filterByCircularity=True\n",
    "params.minCircularity=0.9\n",
    "\n",
    "#Set Convexity filtering parameters\n",
    "params.filterByConvexity=False\n",
    "params.minConvexity=0.2\n",
    "\n",
    "#Set inertia filtering parameters\n",
    "params.filterByInertia=True\n",
    "params.minInertiaRatio=0.01\n",
    "\n",
    "#Create a detector with the parameters\n",
    "detector=cv2.SimpleBlobDetector_create(params)\n",
    "#Detect blobs\n",
    "keypoints=detector.detect(image)\n",
    "# Draw blobs on our image as red circles\n",
    "blank = np.zeros((1,1)) \n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (0,255,0),\n",
    "                                      cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "number_of_blobs=len(keypoints)\n",
    "text='Number of Circular Blobs:'+ str(len(keypoints))\n",
    "cv2.putText(blobs,text,(20,550),cv2.FONT_HERSHEY_SIMPLEX,1,(0,100,255),2)\n",
    "#Show blobs\n",
    "cv2.imshow('Filtering Circular Blobs only',blobs)\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** OpenCV 3.XX, use this line of code for intializing our blob detector\n",
    "\n",
    "`detector = cv2.SimpleBlobDetector_create(params)`\n",
    "\n",
    "OpenCV 2.4.X users use this:\n",
    "\n",
    "`detector = cv2.SimpleBlobDetector()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
