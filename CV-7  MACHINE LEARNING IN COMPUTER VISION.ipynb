{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is machine learning?\n",
    "- Machine learning is a field of AI that gives computers the ability to learn from data,make decisions and predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Project # 9.1- Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep, Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us take a look at our digitals dataset\n",
    "image=cv2.imread('images/digits.png')\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "small=cv2.pyrDown(image)\n",
    "cv2.imshow('Digits Image',small)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "#Split the image to 5000 cells,each 20X20 \n",
    "#This gives us a 4-dim array: (50raws) x (100cols) x (20x20 each cell)\n",
    "cells=[np.hsplit(row,100) for row in np.vsplit(gray,50)]\n",
    "#Convert the List data type to Numpy Array of shape (50,100,20,20)\n",
    "x=np.array(cells)\n",
    "print('The shape of our cells array:'+ str(x.shape))\n",
    "\n",
    "#Split the full data set into two segments\n",
    "#One will be used for Training the model, the other as a test data set\n",
    "train=x[:,:70].reshape(-1,400).astype(np.float32)# Size = (3500,400)\n",
    "test=x[:,70:100].reshape(-1,400).astype(np.float32)# Size = (1500,400)\n",
    "\n",
    "#Create labels for training and test data\n",
    "k=[0,1,2,3,4,5,6,7,8,9]\n",
    "train_labels=np.repeat(k,350)[:,np.newaxis]\n",
    "test_labels=np.repeat(k,150)[:,np.newaxis]\n",
    "\n",
    "#Initiate the kNN,train the data, then test it with test data for k=3\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train,cv2.ml.ROW_SAMPLE, train_labels)\n",
    "ret, result, neighbors, distance = knn.findNearest(test, k=3)\n",
    "\n",
    "#Now we check the accuracy of classification\n",
    "#For that,compare the result with test_labels and check which are wrong\n",
    "matches=result==test_labels\n",
    "correct=np.count_nonzero(matches)\n",
    "accuracy=correct*(100.0/result.size)\n",
    "print('Accuracy is = ',accuracy,'%')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining some functions we will use to prepare an input image\n",
    "\n",
    "### Useful function:      cv2.copyMakeBorder(....)\n",
    "- Get the input image, then compute h an w, if h>w, calculate the difference then do:\n",
    "- 1. add the difference/2 on the left of w \n",
    "- 2. add the difference/2 on the right of w.\n",
    "- OutputImage=cv2.copyMakeBorder(inputImage,top,bottom,left,right,borderType,const Scalar & value = Scalar())\n",
    "\n",
    "- if w>h do it on both top and buttom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our functions\n",
    "\n",
    "def x_cord_contour(contours):\n",
    "    # This function take a contour from findContours\n",
    "    # it then outputs the x centroid coordinates\n",
    "    if cv2.contourArea(contours) >= 10:\n",
    "        M = cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def makeSquare(not_square):\n",
    "    # This function takes an image and makes the dimenions square\n",
    "    # It adds black pixels as the padding where needed\n",
    "    \n",
    "    BLACK = [0,0,0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    #print(\"Height = \", height, \"Width = \", width)\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square,(2*width, 2*height), interpolation = cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        #print(\"New Height = \", height, \"New Width = \", width)\n",
    "        if (height > width):\n",
    "            pad = int((height - width)/2)\n",
    "            #print(\"Padding = \", pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize,0,0,pad,\\\n",
    "                                                   pad,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "        else:\n",
    "            pad = int((width - height)/2)\n",
    "            #print(\"Padding = \", pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize,pad,pad,0,0,\\\n",
    "                                                   cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    #print(\"Sq Height = \", doublesize_square_dim[0], \"Sq Width = \", doublesize_square_dim[1])\n",
    "    return doublesize_square\n",
    "\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    # This function then re-sizes an image to the specificied dimenions\n",
    "    \n",
    "    buffer_pix = 4\n",
    "    dimensions  = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions) / squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    width_r = img_dim2[1]\n",
    "    BLACK = [0,0,0]\n",
    "    if (height_r > width_r):\n",
    "        resized = cv2.copyMakeBorder(resized,0,0,0,1,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    if (height_r < width_r):\n",
    "        resized = cv2.copyMakeBorder(resized,1,0,0,0,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized,p,p,p,p,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    #print(\"Padded Height = \", height, \"Width = \", width)\n",
    "    return ReSizedImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a new image, preprocessing it and classifying the digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/numbers.jpg')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.imshow(\"gray\", gray)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Blur image then find edges using Canny \n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "cv2.imshow(\"blurred\", blurred)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Finding Canny edges\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "cv2.imshow(\"edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Fint Contours\n",
    "_,contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Sort out contours left to right by using their x cordinates\n",
    "contours = sorted(contours,key = x_cord_contour, reverse = False)# x_cord_contour\n",
    "\n",
    "# Create empty array to store entire number\n",
    "full_number = []\n",
    "\n",
    "# loop over the contours\n",
    "for c in contours:\n",
    "    # compute the bounding box for the rectangle\n",
    "    (x, y, w, h) = cv2.boundingRect(c)    \n",
    "    \n",
    "    cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "    cv2.imshow(\"Contours\", image)\n",
    "\n",
    "    if w >= 5 and h >= 25:\n",
    "        roi = blurred[y:y + h, x:x + w]\n",
    "        ret, roi = cv2.threshold(roi, 127, 255,cv2.THRESH_BINARY_INV)\n",
    "        squared = makeSquare(roi)\n",
    "        final = resize_to_pixel(20, squared)\n",
    "        cv2.imshow(\"final\", final)\n",
    "        final_array = final.reshape((1,400))\n",
    "        final_array = final_array.astype(np.float32)\n",
    "        ret, result, neighbours, dist = knn.findNearest(final_array, k=1)\n",
    "        number = str(int(float(result[0])))\n",
    "        full_number.append(number)\n",
    "        # draw a rectangle around the digit, the show what the\n",
    "        # digit was classified as\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv2.putText(image, number, (x , y + 155),\n",
    "            cv2.FONT_HERSHEY_COMPLEX, 2, (255, 0, 0), 2)\n",
    "        cv2.imshow(\"image\", image)\n",
    "        cv2.waitKey(0) \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "print (\"The number is: \" + ''.join(full_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Project # 9.2-Face Recognition â€“ Unlock Your Computer With Your Face!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  step1 - Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load HAAR face classifier\n",
    "face_classifier=cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "#Load function\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    #otherwise Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face=img[y:y+h, x:x+w]\n",
    "    return cropped_face\n",
    "\n",
    "#Initialize Webcom\n",
    "cap = cv2.VideoCapture(0)\n",
    "count=0\n",
    "#Collect 100 samples of your from webcam input\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count+=1\n",
    "        face=cv2.resize(face_extractor(frame),(200,200))\n",
    "        face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #Save file in specified directory with unique name\n",
    "        file_name_path='./faces/user/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        \n",
    "        #Put count on images and display live count\n",
    "        cv2.putText(face, str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow('Face Cropper',face)\n",
    "       \n",
    "    else:\n",
    "        print('Face not found')\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1)==13 or count==100:#13 is the ENTER KEY\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Collecting Samples Complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating arrays for training data and labels\n",
    "Training_Data, Labels=[],[]\n",
    "\n",
    "#Loading training images with pillow library\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "image_list = []\n",
    "for filename in glob.glob('./faces/user/*.jpg'): #assuming gif\n",
    "    im=Image.open(filename)\n",
    "    #im.show()\n",
    "    image_list.append(np.asarray(im,dtype=np.int))\n",
    "    Labels.append(1)\n",
    "#Labels = np.asarray(Labels, dtype=np.int)    \n",
    "\n",
    "  \n",
    "for filename in glob.glob('./faces1/user/*.jpg'): #assuming gif\n",
    "    im=Image.open(filename)\n",
    "    #im.show()\n",
    "    image_list.append(np.asarray(im,dtype=np.int))\n",
    "    Labels.append(2)  \n",
    "    \n",
    "Labels = np.asarray(Labels, dtype=np.int)\n",
    "\n",
    "\n",
    "#Initialize facial recognizer\n",
    "model=cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "\n",
    "\n",
    "#Let's train our model\n",
    "model.train((image_list),(Labels))\n",
    "model.save(\"face-trainner.yml\")\n",
    "print('model trained sucessfully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier=cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "model=cv2.face.LBPHFaceRecognizer_create()\n",
    "model.read(\"face-trainner.yml\")\n",
    "\n",
    "\n",
    "def face_detector(img,size=0.5):\n",
    "    #Convert image to grayscale\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is():\n",
    "        return img, []\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w, y+h),(0,255,255),2)\n",
    "        roi=img[y:y+h, x:x+w]\n",
    "        roi=cv2.resize(roi,(200,200))\n",
    "    return img, roi\n",
    "\n",
    "#Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    image,face=face_detector(frame)\n",
    "    try:\n",
    "        face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results=model.predict(face)\n",
    "        id_, conf = model.predict(face)\n",
    "        print(id_)\n",
    "        print(conf)\n",
    "    \n",
    "        if results[1]<500:\n",
    "            confidence = int(100*(1-(results[1])/400)) \n",
    "            display_string=str(confidence)+'% Confident is is User'\n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)    \n",
    "\n",
    "        if confidence > 75 and id_==1:\n",
    "             cv2.putText(image, \"Cesar-Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "             cv2.imshow('Face Recognition', image )\n",
    "            \n",
    "        elif confidence > 75 and id_==2:\n",
    "             cv2.putText(image, \"xxxx-Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "             cv2.imshow('Face Recognition', image )           \n",
    "            \n",
    "        else:\n",
    "             cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "             cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))#__file__\n",
    "image_dir = os.path.join(BASE_DIR, \"images1\")\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('cascades/data/haarcascade_frontalface_alt2.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "current_id = 0\n",
    "label_ids = {}\n",
    "y_labels = []\n",
    "x_train = []\n",
    "\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path = os.path.join(root, file)\n",
    "            label = os.path.basename(root).replace(\" \", \"-\").lower()\n",
    "            #print(label, path)\n",
    "            if not label in label_ids:\n",
    "                label_ids[label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = label_ids[label]\n",
    "            #print(label_ids)\n",
    "            #y_labels.append(label) # some number\n",
    "            #x_train.append(path) # verify this image, turn into a NUMPY arrray, GRAY\n",
    "            pil_image = Image.open(path).convert(\"L\") # grayscale\n",
    "            size = (550, 550)\n",
    "            final_image = pil_image.resize(size, Image.ANTIALIAS)\n",
    "            image_array = np.array(final_image, \"uint8\")\n",
    "            #print(image_array)\n",
    "            faces = face_cascade.detectMultiScale(image_array, scaleFactor=1.5, minNeighbors=5)\n",
    "\n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = image_array[y:y+h, x:x+w]\n",
    "                x_train.append(roi)\n",
    "                y_labels.append(id_)\n",
    "\n",
    "\n",
    "#print(y_labels)\n",
    "#print(x_train)\n",
    "\n",
    "with open(\"pickles/face-labels.pickle\", 'wb') as f:\n",
    "    pickle.dump(label_ids, f)\n",
    "\n",
    "recognizer.train(x_train, np.array(y_labels))\n",
    "recognizer.save(\"recognizers/face-trainner.yml\")\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('cascades/data/haarcascade_frontalface_alt2.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('cascades/data/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('cascades/data/haarcascade_smile.xml')\n",
    "\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"./recognizors/face-trainner.yml\")\n",
    "\n",
    "labels = {\"person_name\": 1}\n",
    "with open(\"pickles/face-labels.pickle\", 'rb') as f:\n",
    "\tog_labels = pickle.load(f)\n",
    "\tlabels = {v:k for k,v in og_labels.items()}\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)\n",
    "    for (x, y, w, h) in faces:\n",
    "    \t#print(x,y,w,h)\n",
    "    \troi_gray = gray[y:y+h, x:x+w] #(ycord_start, ycord_end)\n",
    "    \troi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "    \t# recognize? deep learned model predict keras tensorflow pytorch scikit learn\n",
    "    \tid_, conf = recognizer.predict(roi_gray)\n",
    "    \tif conf>=4 and conf <= 85:\n",
    "    \t\t#print(5: #id_)\n",
    "    \t\t#print(labels[id_])\n",
    "    \t\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \t\tname = labels[id_]\n",
    "    \t\tcolor = (255, 255, 255)\n",
    "    \t\tstroke = 2\n",
    "    \t\tcv2.putText(frame, name, (x,y), font, 1, color, stroke, cv2.LINE_AA)\n",
    "\n",
    "    \timg_item = \"7.png\"\n",
    "    \tcv2.imwrite(img_item, roi_color)\n",
    "\n",
    "    \tcolor = (255, 0, 0) #BGR 0-255 \n",
    "    \tstroke = 2\n",
    "    \tend_cord_x = x + w\n",
    "    \tend_cord_y = y + h\n",
    "    \tcv2.rectangle(frame, (x, y), (end_cord_x, end_cord_y), color, stroke)\n",
    "    \t#subitems = smile_cascade.detectMultiScale(roi_gray)\n",
    "    \t#for (ex,ey,ew,eh) in subitems:\n",
    "    \t#\tcv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "'''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
