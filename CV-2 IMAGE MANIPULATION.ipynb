{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our input image\n",
    "image = cv2.imread('images/input.jpg')\n",
    "#store height and width of the image\n",
    "height, width =image.shape[:2]\n",
    "quarter_height, quarter_width = height/4, width/4\n",
    "\n",
    "# let us create our translation matrix\n",
    "#     |1 0 Tx|\n",
    "# T = |1 0 Ty|\n",
    "T=np.float32([[1,0,quarter_width],[0,1,quarter_height]])\n",
    "#print(T)\n",
    "# We use warpAffine and T transform the image\n",
    "img_translation = cv2.warpAffine(image, T,(width,height))\n",
    "cv2.imshow('Translated',img_translation)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/input.jpg')\n",
    "height, width = image.shape[:2]\n",
    "#Let us create the Rotation matrix\n",
    "#cv2.getRotationMatrix2D(rotation_center_x, rotation_center_y, angle of rotation, scale)\n",
    "rotation_matrix=cv2.getRotationMatrix2D((width/2,height/3),90,.5)\n",
    "#print(rotation_matrix)\n",
    "rotated_image=cv2.warpAffine(image,rotation_matrix,(width,height))\n",
    "cv2.imshow('Rotated Image', rotated_image)\n",
    "\n",
    "#Other Option to Rotate\n",
    "img = cv2.imread('images/input.jpg')\n",
    "rotated_image2=cv2.transpose(img)\n",
    "cv2.imshow('Rotated Image - Method 2',rotated_image2)#no black adges included\n",
    "\n",
    "# Let's now to a horizontal flip.\n",
    "img2 = cv2.imread('images/input.jpg')\n",
    "flipped = cv2.flip(img2, 1)\n",
    "cv2.imshow('Horizontal Flip', flipped) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling, Re-sizing and interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/input.jpg')\n",
    "#cv2.resize(image, dsize(output image size), x scale, y scale, interpolation)\n",
    "\n",
    "# Let's make our image 3/4 of it's original size\n",
    "image_scaled =  cv2.resize(image,None,fx=0.50,fy=0.50)\n",
    "cv2.imshow('Scaling - Linear Interpolation',image_scaled)\n",
    "\n",
    "# Let's double the size of our image\n",
    "img_scaled = cv2.resize(image, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interpolation', img_scaled)\n",
    "\n",
    "# Let's skew the re-sizing by setting exact dimensions\n",
    "img_scaled = cv2.resize(image,(900,400), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - Skewed Size', img_scaled)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful when scaling images in object detection.\n",
    "image = cv2.imread('images/input.jpg')\n",
    "smaller=cv2.pyrDown(image)\n",
    "larger = cv2.pyrUp(smaller)\n",
    "\n",
    "cv2.imshow('Original',image)\n",
    "cv2.imshow('Smaller',smaller)\n",
    "cv2.imshow('Larger',larger)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/input.jpg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "\n",
    "#starting pixel coordiantes (top  left of cropping rectangle)\n",
    "start_row, start_col = int(height * .25), int(width * .25)\n",
    "#ending pixel coordinates (bottom right)\n",
    "end_row, end_col = int(height * .75), int(width * .75)\n",
    "#use indexing to crop out the rectangle we desire\n",
    "cropped = image[start_row:end_row , start_col:end_col]\n",
    "\n",
    "# Simply use indexing to crop out the rectangle we desire\n",
    "cropped = image[start_row:end_row, start_col:end_col]\n",
    "\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Cropped Image\", cropped)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/input.jpg')\n",
    "\n",
    "# Create a matrix of ones, then multiply it by a scaler of 100\n",
    "#with same dimesions of our image\n",
    "M = np.ones(image.shape,dtype='uint8')*100\n",
    "\n",
    "added=cv2.add(image,M)#Add M to our image\n",
    "subtracted=cv2.subtract(image,M)#Subtract M from our image\n",
    "cv2.imshow(\"Added\", added)\n",
    "cv2.imshow(\"Subtracted\", subtracted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitwise Operation and Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a square\n",
    "square= np.zeros((300, 300),np.uint8)\n",
    "cv2.rectangle(square, (50,50),(250,250),255, -2)\n",
    "cv2.imshow('Square',square)\n",
    "\n",
    "#Making an ellipse\n",
    "ellipse= np.zeros((300, 300), np.uint8)\n",
    "cv2.ellipse(ellipse,(150, 150),(150, 150),60, 0,180,255, -1)\n",
    "cv2.imshow('Ellipse',ellipse)\n",
    "\n",
    "\n",
    "#Experimenting with some Bitwise Operations\n",
    "BitwiseAnd=cv2.bitwise_and(square, ellipse)# shows intersection\n",
    "cv2.imshow('AND',BitwiseAnd)\n",
    "BitwiseOr=cv2.bitwise_or(square, ellipse)#shows union \n",
    "cv2.imshow('OR',BitwiseOr)\n",
    "bitwiseXor=cv2.bitwise_xor(square,ellipse)#shows union minus interaction\n",
    "cv2.imshow('XOR', bitwiseXor)\n",
    "BitwiseNot_sq=cv2.bitwise_not(square)#show the oposite\n",
    "cv2.imshow('NOT - Square',BitwiseNot_sq)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/elephant.jpg')\n",
    "cv2.imshow('Original Image',image)\n",
    "\n",
    "#create 3x3 kernel\n",
    "kernel_3x3=np.ones((3,3),np.float32)/9\n",
    "#create 7x7 kernel\n",
    "kernel_7x7=np.ones((7,7),np.float32)/49\n",
    "\n",
    "#Now let us use cv2.filter2D to convolve the kernel with an image\n",
    "blurred = cv2.filter2D(image, -1,kernel_3x3)\n",
    "cv2.imshow('3x3 Kernel Blurring',blurred)\n",
    "blurred1 = cv2.filter2D(image, -1,kernel_7x7)\n",
    "cv2.imshow('7x7 Kernel Blurring',blurred)\n",
    "\n",
    "#Other used blurring methods in Opencv\n",
    "blur=cv2.blur(image,(3,3))\n",
    "cv2.imshow('Averaging',blur)#central element is replaced with AVERAGE value\n",
    "Gaussian=cv2.GaussianBlur(image,(7,7),0)\n",
    "cv2.imshow('Gaussian Blurring',Gaussian)#check gaussian filter online\n",
    "median=cv2.medianBlur(image,5)\n",
    "cv2.imshow('Median Blurring',median)#central element is replaced with MEDIAN value\n",
    "bilateral=cv2.bilateralFilter(image,9, 75, 75)\n",
    "cv2.imshow('Bilateral Blurring',bilateral)\n",
    "\n",
    "#Image De-noising - Non-Local Means Denoising\n",
    "\n",
    "# Parameters, after None are - the filter strength 'h' (5-10 is a good range)\n",
    "# Next is hForColorComponents, set as same value as h again\n",
    "dst=cv2.fastNlMeansDenoisingColored(image,None, 6,6,7,21)\n",
    "cv2.imshow('Fast Means Denoising',dst)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 4 variations of Non-Local Means Denoising:**\n",
    "\n",
    "- cv2.fastNlMeansDenoising() - works with a single grayscale images\n",
    "- cv2.fastNlMeansDenoisingColored() - works with a color image.\n",
    "- cv2.fastNlMeansDenoisingMulti() - works with image sequence captured in short period of time (grayscale images)\n",
    "- cv2.fastNlMeansDenoisingColoredMulti() - same as above, but for color images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpening \n",
    "-strengthening or emphasizing edges in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('images/input.jpg')\n",
    "kernel_sharpening= np.array([[-1,-1,-1],\n",
    "                             [-1,9,-1],\n",
    "                             [-1,-1,-1]])\n",
    "sharpened=cv2.filter2D(image, -1,kernel_sharpening)\n",
    "cv2.imshow('image Sharpening',sharpened)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding, Binarization & Adaptive Thresholding\n",
    "\n",
    "\n",
    "In thresholding, we convert a grey scale image to it's binary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('images/gradient.jpg',0)\n",
    "cv2.imshow('Original',image)\n",
    "\n",
    "# Values below 127 goes to 0\n",
    "ret,thresh1=cv2.threshold(image,127,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('1 Threshold Binary Inverse', thresh1)\n",
    "\n",
    "# Values below 127 go to 255 \n",
    "ret,thresh2=cv2.threshold(image,127,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('2 Threshold Binary Inverse',thresh2)\n",
    "\n",
    "# Values above 127 are truncated (held) at 127\n",
    "ret,thresh3=cv2.threshold(image,127,255,cv2.THRESH_TRUNC)\n",
    "cv2.imshow('3 THRESH TRUNC', thresh3)\n",
    "\n",
    "# Values below 127 go to 0, above 127 are unchanged \n",
    "ret,thresh4=cv2.threshold(image,127,255,cv2.THRESH_TOZERO)\n",
    "cv2.imshow('4 THRESH TOZERO', thresh4)\n",
    "\n",
    "# Resever of above, below 127 is unchanged, above 127 goes to 0\n",
    "ret,thresh5=cv2.threshold(image,127,255,cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('5 THRESH TOZERO INV', thresh5)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive Thresholding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('images/Origin_of_Species.jpg',0)\n",
    "cv2.imshow('Original',image)\n",
    "\n",
    "# Values below 127 goes to 0 (black, everything above goes to 255 (white)\n",
    "ret,thresh1=cv2.threshold(image, 127,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold Binary',thresh1)\n",
    "\n",
    "# It's good practice to blur images as it removes noise\n",
    "image=cv2.GaussianBlur(image,(3,3),0)\n",
    "\n",
    "# Using adaptiveThreshold\n",
    "thresh=cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                             cv2.THRESH_BINARY, 3, 5)\n",
    "cv2.imshow('Adaptive Mean Thresholding',thresh)\n",
    "\n",
    "\n",
    "ret,th2=cv2.threshold(image,0,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Otsu's Thresholding\",th2)\n",
    "\n",
    " \n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation, Erosion, Opening and Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('images/opencv_inv.png',0)\n",
    "cv2.imshow('Original',image)\n",
    "\n",
    "#Defining kernel size\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "\n",
    "\n",
    "erosion=cv2.erode(image,kernel,iterations=1)#Erosion\n",
    "cv2.imshow('Erosion',erosion)\n",
    "dilation=cv2.dilate(image,kernel,iterations=1)#Dilation\n",
    "cv2.imshow('Dilation',dilation)\n",
    "\n",
    "#Opening -  Good for removing noise\n",
    "opening=cv2.morphologyEx(image,cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Opening',opening)\n",
    "#Closing(the erosion of the dilation ) - Good for removing noise\n",
    "closing=cv2.morphologyEx(image,cv2.MORPH_CLOSE,kernel)\n",
    "cv2.imshow('Closing',closing)\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection and Image Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('images/input.jpg',0)\n",
    "height, width=image.shape\n",
    "\n",
    "#Extract Sobel Edges\n",
    "sobel_x=cv2.Sobel(image,cv2.CV_64F, 0,1, ksize=5)\n",
    "sobel_y=cv2.Sobel(image,cv2.CV_64F, 1,0, ksize=5)\n",
    "sobel_OR=cv2.bitwise_or(sobel_x, sobel_y)\n",
    "\n",
    "cv2.imshow('Original',image)\n",
    "cv2.imshow('Sobel_x',sobel_x)\n",
    "cv2.imshow('Sobel_y',sobel_y)\n",
    "cv2.imshow('Sobel_OR',sobel_OR)\n",
    "\n",
    "\n",
    "laplacian=cv2.Laplacian(image,cv2.CV_64F)\n",
    "canny=cv2.Canny(image,100,120)\n",
    "#we need to provide two values: threshold1 and threshold2. Any gradient value larger than threshold2\n",
    "# is considered to be an edge. Any value below threshold1 is considered not to be an edge. \n",
    "#Values in between threshold1 and threshold2 are either classiﬁed as edges or non-edges based on how their \n",
    "#intensities are “connected”. In this case, any gradient values below 60 are considered non-edges\n",
    "#whereas any values above 120 are considered edges.\n",
    "\n",
    "\n",
    "cv2.imshow('Laplacian',laplacian)\n",
    "cv2.imshow('Canny',canny)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('images/scan.jpg')\n",
    "cv2.imshow('Original',image)\n",
    "\n",
    "#Cordinates of the 4 corners of the original image\n",
    "points_A=np.float32([[320,15],[700,215],[85,610],[530,780]])\n",
    "\n",
    "# Cordinates of the 4 corners of the desired output\n",
    "# We use a ratio of an A4 Paper 1 : 1.41\n",
    "points_B=np.float32([[0,0],[420,0],[0,594],[420,594]])\n",
    "\n",
    "\n",
    "# Use the two sets of four points to compute \n",
    "# the Perspective Transformation matrix, M  \n",
    "M=cv2.getPerspectiveTransform(points_A,points_B)\n",
    "warped=cv2.warpPerspective(image,M,(420,594))\n",
    "cv2.imshow('warpPerspective',warped)\n",
    "\n",
    "#-------only need 3 coordinates in affine transforms------------------------\n",
    "image2=cv2.imread('images/ex2.jpg')\n",
    "rows,cols,ch=image.shape\n",
    "cv2.imshow('Original2',image2)\n",
    "\n",
    "\n",
    "# Cordinates of the 4 corners of the original image\n",
    "points_C =np.float32([[320,15],[700,215],[85,610]])\n",
    "\n",
    "# Cordinates of the 4 corners of the desired output\n",
    "# We use a ratio of an A4 Paper 1 : 1.41\n",
    "points_D =np.float32([[0,0],[420,0],[0,594]])\n",
    "\n",
    " \n",
    "# Use the two sets of four points to compute \n",
    "# the Perspective Transformation matrix, M  \n",
    "M=cv2.getAffineTransform(points_C, points_D)\n",
    "warped2=cv2.warpAffine(image2, M,(cols, rows))\n",
    "cv2.imshow('warpPerspective2',warped2)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Project # 1 - Live Sketch Using Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Our sketch generating function\n",
    "def sketch(image):\n",
    "    #Convert image to grayscale\n",
    "    img_gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Clean up image using Guassian Blur\n",
    "    img_gray_blur=cv2.GaussianBlur(img_gray, (5,5),0)\n",
    "    \n",
    "    #Extract edges\n",
    "    canny_edges=cv2.Canny(img_gray_blur,10,70)\n",
    "    \n",
    "    #Do an invert binarize the image\n",
    "    ret,mask=cv2.threshold(canny_edges, 70,255,cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "# Initialize webcam, cap is the object provided by VideoCapture\n",
    "# It contains a boolean indicating if it was sucessful (ret)\n",
    "# It also contains the images collected from the webcam (frame)\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    #height,width=frame.shape[:2]\n",
    "    cv2.imshow('Our Live Sketcher',sketch(frame))\n",
    "    if cv2.waitKey(1)==13:#13 is the Enter Key on your computer\n",
    "        break\n",
    "        \n",
    "#Release camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
